{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN99KEkv1T1AgNGUM88GYnf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khenm/email_classification/blob/develop/text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Text Classification**\n",
        "<p align=\"justify\">\n",
        "Text Classification is an important machine learning task in Natural Language Processing. Our task is to build a program to classifiy texts into given categories. Some applications of this task are spam detection, sentiment analysis and topic classification,...\n",
        "In this project, we will build a Text Classification program to differentiate between spam and ham messages by using Naive Bayes algorithm.\n",
        "</p>"
      ],
      "metadata": {
        "id": "6rWiVUr-gSZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download data\n",
        "!gdown --id 1N7rk-kfnDFIGMeX0ROVTjKh71gcgx-7R"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WX1uL1VhgViu",
        "outputId": "09952e50-117b-4c63-822c-e1a68e96ebf8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1N7rk-kfnDFIGMeX0ROVTjKh71gcgx-7R\n",
            "To: /content/2cls_spam_text_cls.csv\n",
            "100% 486k/486k [00:00<00:00, 73.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-WwSIZ_ggrk",
        "outputId": "8922429a-0120-470a-b154-247bc46a29f1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data\n",
        "DATASET_PATH = '/content/2cls_spam_text_cls.csv'\n",
        "df = pd.read_csv(DATASET_PATH)\n",
        "\n",
        "messages = df['Message'].values.tolist()\n",
        "labels = df['Category'].values.tolist()"
      ],
      "metadata": {
        "id": "kUwrKVuKhMDn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Preprocessing features**\n",
        "<p align=\"justify\">\n",
        "The content in Messages is diversed and comprised of different combinations of words and characters. In special cases, it can be abbreviations, meaningless words, and its family words. Thus, it is important to handle these words in advance. In this section, we will progress through this pipeline:\n",
        "\n",
        "Message ⟶ Lowercase ⟶ Punctuation Removal ⟶ Tokenizer ⟶ Remove Stopwords ⟶ Stemming\n",
        "</p>"
      ],
      "metadata": {
        "id": "zoORjkAeiL8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prehandling\n",
        "def lowercase(text):\n",
        "    return text.lower()\n",
        "\n",
        "\n",
        "def punctuation_removal(text):\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    return text.translate(translator)\n",
        "\n",
        "\n",
        "def tokenize(text):\n",
        "    return nltk.word_tokenize(text)\n",
        "\n",
        "\n",
        "def remove_stopwords(tokens):\n",
        "    stop_words = nltk.corpus.stopwords.words('english')\n",
        "    return [token for token in tokens if token not in stop_words]\n",
        "\n",
        "\n",
        "def stemming(tokens):\n",
        "    stemmer = nltk.stem.PorterStemmer()\n",
        "    return [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = lowercase(text)\n",
        "    text = punctuation_removal(text)\n",
        "    tokens = tokenize(text)\n",
        "    tokens = remove_stopwords(tokens)\n",
        "    tokens = stemming(tokens)\n",
        "    return tokens\n",
        "\n",
        "\n",
        "messages = [preprocess_text(message) for message in messages]"
      ],
      "metadata": {
        "id": "fdfXWKHukNLO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary\n",
        "def create_dictionary(messages):\n",
        "    dictionary = []\n",
        "    for tokens in messages:\n",
        "        for token in tokens:\n",
        "            if token not in dictionary:\n",
        "                dictionary.append(token)\n",
        "    dictionarya = sorted(dictionary)\n",
        "    return dictionary\n",
        "\n",
        "\n",
        "dictionary = create_dictionary(messages)"
      ],
      "metadata": {
        "id": "h91evmzxlnKj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we have to create features of each message by counting the frequency of each word in the message. The result will be a vector."
      ],
      "metadata": {
        "id": "iUXOFdR8mNYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_features(tokens, dictionary):\n",
        "    features = np.zeros(len(dictionary))\n",
        "    for token in tokens:\n",
        "        if token in dictionary:\n",
        "            features[dictionary.index(token)] += 1\n",
        "    return features\n",
        "\n",
        "\n",
        "X = np.array([create_features(tokens, dictionary) for tokens in messages])"
      ],
      "metadata": {
        "id": "HxpY2C61mEkb"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing the labels\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(labels)\n",
        "print(f'Classes: {le.classes_}')\n",
        "print(f'Encoded labels: {y}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLs8Ga1lnBJc",
        "outputId": "ff94f5df-4ef6-4b78-c1e7-ade24c2ef577"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['ham' 'spam']\n",
            "Encoded labels: [0 0 1 ... 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Splitting train/val/test**\n",
        "<p align='justify'>\n",
        "To train a model, we don't take the whole dataset to train but split it into 3 different subsets: Train, Validation and Test (7/2/1). Besides, to guarantee the same results for each time, we have to fix the SEED.\n",
        "</p>"
      ],
      "metadata": {
        "id": "mv3sCC7xnXRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VAL_SIZE = 0.2\n",
        "TEST_SIZE = 0.125\n",
        "SEED = 0\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y,\n",
        "    test_size=VAL_SIZE,\n",
        "    shuffle=True,\n",
        "    random_state=SEED\n",
        ")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_train, y_train,\n",
        "    test_size=TEST_SIZE,\n",
        "    shuffle=True,\n",
        "    random_state=SEED\n",
        ")"
      ],
      "metadata": {
        "id": "vN3_pN_JoUR4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Train the Model**\n",
        "<p align='justify'>\n",
        "In this part, we will use sklearn library and pass the inputs to Gaussian Naive Bayes model to train\n",
        "</p>"
      ],
      "metadata": {
        "id": "E3wYZYg5sfUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = GaussianNB()\n",
        "print('Start Training...')\n",
        "model = model.fit(X_train, y_train)\n",
        "print('Training completed!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPXMidzWs4Ws",
        "outputId": "af8c0e4f-2503-46f0-f4b8-8b7e87c75478"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Training...\n",
            "Training completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model Evaluation**\n",
        "<p align='justify'>\n",
        "After training, the next step is to evaluate the model's performance. Beginning with testing the trained model on Validation and Test set, then, we will use Accuracy Score to assess the model.\n",
        "</p>"
      ],
      "metadata": {
        "id": "LL0SPZuBt1wK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_pred = model.predict(X_val)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "print(f'Val accuracy: {val_accuracy}')\n",
        "print(f'Test accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMP56pzOvaHh",
        "outputId": "9e5c3471-f7c6-46bd-d686-b081fcaaf608"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val accuracy: 0.8816143497757848\n",
            "Test accuracy: 0.8602150537634409\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Prediction**\n",
        "<p align='justify'>\n",
        "Now,  we can use this model for new Message, we have to start from scratch: preprocessing, creating features, and fitting to the model. The output of the model will give 0 or 1, therefore, to get the correct label, we use inverse_transform().\n",
        "</p>"
      ],
      "metadata": {
        "id": "bKrmsvFNwohY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(text, model, dictionary):\n",
        "    processed_text = preprocess_text(text)\n",
        "    features = create_features(processed_text, dictionary)\n",
        "    features = np.array(features).reshape(1, -1)\n",
        "    prediction = model.predict(features)\n",
        "    prediction_cls = le.inverse_transform(prediction)[0]\n",
        "    return prediction_cls\n",
        "\n",
        "test_input = 'I am actually thinking a way of doing something useful'\n",
        "prediction_cls = predict(test_input, model, dictionary)\n",
        "print(f'Prediction: {prediction_cls}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIZCC3zKxV3A",
        "outputId": "316ab45e-df4f-4a71-d1d2-f19eb7abebbd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: ham\n"
          ]
        }
      ]
    }
  ]
}